# CALM - Contrastive Alignment of Language and Music

Project for the ``1st Sound of AI Hackathon``

Group composed by *Alkis Koudounas*, *Lorenzo Vaiani*, *Moreno La Quatra*.

![CALM](images/logo.png?raw=true)

***

## What we propose
In a nutshell: our idea is to align songs with their natural language description such that we can use text, voice or facial expression to search music.

![Architecture](images/basic_architecture_v2.png?raw=true)

***

## Who is our target
People using music streaming services:
* Casual listeners 
* Explorers
* Public places

***

## What is our impact
``CALM`` will have a direct impact on:
* People using streaming service. Explore new music everyday.
* New releases that may be immediately included in search.
* People who can search using multiple modalities.

***

## A small DEMO
Here is a small overview of our web application.
![App](images/app.png?raw=true)

For a complete demo, you can have a look here!

[![Watch our Demo](images/demo.png)](https://www.youtube.com/watch?v=ljVF8ZSoVY0)

***

## ü§åüèª About the project 
CALM is a project created by [Alkis Koudounas](https://koudounasalkis.github.io), [Lorenzo Vaiani](https://twitter.com/VaianiLorenzo), and [Moreno La Quatra](https://www.mlaquatra.me). It is part of the ***The 1st Sound of AI Hackathon***.

<p align="center">
  <img src="images/ALM.png" alt="logo" width="300"/>
</p>
